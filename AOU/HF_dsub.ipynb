{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## write dsub file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile ~/aou_dsub.bash\n",
    "\n",
    "#!/bin/bash\n",
    "\n",
    "# This shell function passes reasonable defaults for several dsub parameters, while\n",
    "# allowing the caller to override any of them. It creates a nice folder structure within\n",
    "# the workspace bucket for dsub log files.\n",
    "\n",
    "# --[ Parameters ]--\n",
    "# any valid dsub parameter flag\n",
    "\n",
    "#--[ Returns ]--\n",
    "# the job id of the job created by dsub\n",
    "\n",
    "#--[ Details ]--\n",
    "# The first five parameters below should always be those values when running on AoU RWB.\n",
    "\n",
    "# Feel free to change the values for --user, --regions, --logging, and --image if you like.\n",
    "\n",
    "# Note that we insert some job data into the logging path.\n",
    "# https://github.com/DataBiosphere/dsub/blob/main/docs/logging.md#inserting-job-data\n",
    "\n",
    "function aou_dsub () {\n",
    "\n",
    "  # Get a shorter username to leave more characters for the job name.\n",
    "  local DSUB_USER_NAME=\"$(echo \"${OWNER_EMAIL}\" | cut -d@ -f1)\"\n",
    "\n",
    "  # For AoU RWB projects network name is \"network\".\n",
    "  #local AOU_NETWORK=network\n",
    "  #local AOU_SUBNETWORK=subnetwork\n",
    "\n",
    "  dsub \\\n",
    "      --provider google-batch \\\n",
    "      --user-project \"${GOOGLE_PROJECT}\"\\\n",
    "      --project \"${GOOGLE_PROJECT}\"\\\n",
    "      --image 'ubuntu:latest' \\\n",
    "      --network \"global/networks/network\" \\\n",
    "      --subnetwork \"regions/us-central1/subnetworks/subnetwork\" \\\n",
    "      --service-account \"$(gcloud config get-value account)\" \\\n",
    "      --use-private-address \\\n",
    "      --user \"${DSUB_USER_NAME}\" \\\n",
    "      --regions us-central1 \\\n",
    "      --logging \"${WORKSPACE_BUCKET}/dsub/logs/{job-name}/{user-id}/$(date +'%Y%m%d/%H%M%S')/{job-id}-{task-id}-{task-attempt}.log\" \\\n",
    "      \"$@\"\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# subset plink files to variants in scores and individuals in sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copy plink files to workspace bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -u $GOOGLE_PROJECT -m cp gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/acaf_threshold/pgen/* ${WORKSPACE_BUCKET}/HF/input/acaf/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -u $GOOGLE_PROJECT ls -lh gs://fc-aou-datasets-controlled/v8/wgs/short_read/snpindel/acaf_threshold/pgen/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "USER_NAME = os.getenv('OWNER_EMAIL').split('@')[0].replace('.','-')\n",
    "%env USER_NAME={USER_NAME}\n",
    "JOB_NAME=f'plink_subset-{USER_NAME}'\n",
    "%env JOB_NAME={JOB_NAME}\n",
    "\n",
    "params_df = pd.DataFrame(data={\n",
    "    '--env CHROM': [x for x in range(1,23)],\n",
    "    '--output-recursive OUT_DIR': [f\"{bucket}/HF/input/acaf_pgen_subset/\" for _ in range(22)]\n",
    "})\n",
    "\n",
    "PARAMETER_FILENAME = f'{JOB_NAME}_params.tsv'\n",
    "%env PARAMETER_FILENAME={PARAMETER_FILENAME}\n",
    "\n",
    "params_df.to_csv(PARAMETER_FILENAME, sep='\\t', index=False)\n",
    "\n",
    "job_output = !source ~/aou_dsub.bash; aou_dsub \\\n",
    "  --name \"${JOB_NAME}\" \\\n",
    "  --provider google-cls-v2 \\\n",
    "  --image \"gcr.io/ritchie-aou-psom-9015/plink2:latest\" \\\n",
    "  --logging \"${WORKSPACE_BUCKET}/dsub_logs/plink_subset\" \\\n",
    "  --disk-size 180 \\\n",
    "  --mount BUCKET=\"${WORKSPACE_BUCKET}\" \\\n",
    "  --tasks \"${PARAMETER_FILENAME}\" \\\n",
    "  --command 'plink2 --pfile $BUCKET/HF/input/acaf/acaf_threshold.chr$CHROM \\\n",
    "                      --extract range $BUCKET/HF/input/HF.PGS005097.var_list.txt \\\n",
    "                      --set-all-var-ids @:#:\\$r:$a \\\n",
    "                      --new-id-max-allele-len 1000 \\\n",
    "                      --make-pgen \\\n",
    "                      --out $OUT_DIR/acaf_threshold.hf_pgs_weights_vars.chr$CHROM'\n",
    "\n",
    "print(\"\\n\".join(job_output))\n",
    "plink_job_id = job_output[1].split(\" \")[-1]\n",
    "%env PLINK_JOB_ID={plink_job_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check worker status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dstat \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --location us-central1 \\\n",
    "    --jobs \"plink-subs--kathleen-cardone--250702-175543-72\" \\\n",
    "    --users \"kathleen-cardone\" \\\n",
    "    --status '*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls -lh ${WORKSPACE_BUCKET}/HF/input/acaf_pgen_subset/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp ${WORKSPACE_BUCKET}/HF/input/acaf_pgen_subset/acaf_threshold.hf_pgs_weights_vars.chr1.psam .\n",
    "!wc -l acaf_threshold.hf_pgs_weights_vars.chr1.psam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp ${WORKSPACE_BUCKET}/HF/input/acaf_pgen_subset/acaf_threshold.hf_pgs_weights_vars.chr1.pvar .\n",
    "!wc -l acaf_threshold.hf_pgs_weights_vars.chr1.pvar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## remove plink files from workspace bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil rm ${WORKSPACE_BUCKET}/HF/input/acaf/*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# create sample sheet for PGSC-CALC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create file path list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filepath_list = []\n",
    "for chr in list(range(1,23)):\n",
    "    filepath = '/mnt/data/mount/gs/fc-secure-b117990b-e93e-442c-a994-81f2ca68d4fb/HF/input/acaf_pgen_subset/acaf_threshold.hf_pgs_weights_vars.chr' + str(chr)\n",
    "    filepath_list.append(filepath)\n",
    "print(len(filepath_list))\n",
    "filepath_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "samplesheet = pd.DataFrame(data={'sampleset':'AOU',\n",
    "                                'path_prefix':filepath_list,\n",
    "                                'chrom':list(range(1,23)),\n",
    "                                'format':'pfile'})\n",
    "samplesheet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## export dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samplesheet.to_csv('AOU.HF.PGSC_CALC.samplesheet.csv',index=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copy to workspace bucket"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp AOU.HF.PGSC_CALC.samplesheet.csv ${WORKSPACE_BUCKET}/HF/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run PGSC-calc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## run command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "USER_NAME = os.getenv('OWNER_EMAIL').split('@')[0].replace('.','-')\n",
    "%env USER_NAME={USER_NAME}\n",
    "job_output = []\n",
    "\n",
    "\n",
    "JOB_NAME=f'pgsc_calc'\n",
    "%env JOB_NAME={JOB_NAME}\n",
    "\n",
    "params_df = pd.DataFrame(data={\n",
    "    '--output-recursive OUT_DIR': [f\"{bucket}/HF/output/\"]\n",
    "})\n",
    "\n",
    "PARAMETER_FILENAME = f'params.tsv'\n",
    "%env PARAMETER_FILENAME={PARAMETER_FILENAME}\n",
    "\n",
    "params_df.to_csv(PARAMETER_FILENAME, sep='\\t', index=False)\n",
    "\n",
    "job_output = !source ~/aou_dsub.bash; aou_dsub \\\n",
    "  --name \"${JOB_NAME}\" \\\n",
    "  --provider google-cls-v2 \\\n",
    "  --image \"gcr.io/ritchie-aou-psom-9015/pgsc_calc_general:latest\" \\\n",
    "  --logging \"${WORKSPACE_BUCKET}/dsub_logs/hf/\" \\\n",
    "  --disk-size 512 \\\n",
    "  --boot-disk-size 20 \\\n",
    "  --min-ram 208 \\\n",
    "  --min-cores 32 \\\n",
    "  --mount BUCKET=\"${WORKSPACE_BUCKET}\" \\\n",
    "  --tasks \"${PARAMETER_FILENAME}\" \\\n",
    "  --command 'nextflow run pgscatalog/pgsc_calc -profile conda \\\n",
    "                  --input $BUCKET/CKD/input/AOU.CKD.PGSC_CALC.samplesheet.csv \\\n",
    "                  --scorefile \"$BUCKET/HF/input/pgs_weights/*\" \\\n",
    "                  --target_build GRCh38 \\\n",
    "                  --outdir $OUT_DIR \\\n",
    "                  --max_cpus 32 \\\n",
    "                  --max_memory 208.GB \\\n",
    "                  --min_overlap 0.0 \\\n",
    "                  --max_time 240.h \\\n",
    "                  --run_ancestry $BUCKET/CKD/input/pgsc_HGDP+1kGP_v1.tar.zst \\\n",
    "                  --keep_multiallelic True \\\n",
    "                  --hwe_ref 0 \\\n",
    "                  --pca_maf_target 0.05'\n",
    "\n",
    "job_id = job_output[1].split(\" \")[-1]\n",
    "%env JOB_ID={job_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check worker status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dstat \\\n",
    "    --provider google-cls-v2 \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --location us-central1 \\\n",
    "    --jobs \"pgsc-calc--kathleen-cardone--250703-010752-01\" \\\n",
    "    --users \"kathleen-cardone\" \\\n",
    "    --status '*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp ${WORKSPACE_BUCKET}/dsub_logs/hf/pgsc-calc--kathleen-cardone--250703-010752-01* ."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat pgsc-calc--kathleen-cardone--250703-010752-01.1-stderr.log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!cat pgsc-calc--kathleen-cardone--250703-010752-01.1-stdout.log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IRM feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copy script and inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp hf_training_script.py ${WORKSPACE_BUCKET}/HF/scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp in_progress_pheno_no_missing.csv ${WORKSPACE_BUCKET}/HF/input/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp HF_Clinical_PGS.phenotype.no_missing.variable_transformation.csv ${WORKSPACE_BUCKET}/HF/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit first 500 jobs (to avoid exceeding quota)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "USER_NAME = os.getenv('OWNER_EMAIL').split('@')[0].replace('.','-')\n",
    "%env USER_NAME={USER_NAME}\n",
    "job_output = []\n",
    "\n",
    "\n",
    "JOB_NAME=f'regression'\n",
    "%env JOB_NAME={JOB_NAME}\n",
    "\n",
    "params_df = pd.DataFrame(data={\n",
    "    '--env ITER': list(range(1, 501)),\n",
    "    '--output-recursive OUT_DIR': [f\"{bucket}/HF/output/regressions/train/\" for _ in range(500)]\n",
    "})\n",
    "\n",
    "PARAMETER_FILENAME = f'params.tsv'\n",
    "%env PARAMETER_FILENAME={PARAMETER_FILENAME}\n",
    "\n",
    "params_df.to_csv(PARAMETER_FILENAME, sep='\\t', index=False)\n",
    "\n",
    "print('submitting job')\n",
    "\n",
    "job_output = !source ~/aou_dsub.bash; aou_dsub \\\n",
    "  --name \"${JOB_NAME}\" \\\n",
    "  --provider google-batch \\\n",
    "  --image \"gcr.io/ritchie-aou-psom-9015/python:latest\" \\\n",
    "  --logging \"${WORKSPACE_BUCKET}/dsub_logs/hf/regressions/\" \\\n",
    "  --mount BUCKET=\"${WORKSPACE_BUCKET}\" \\\n",
    "  --tasks \"${PARAMETER_FILENAME}\" \\\n",
    "  --command 'python \"${BUCKET}\"/HF/scripts/hf_training_script.py \\\n",
    "                --input \"${BUCKET}\"/HF/input/HF_Clinical_PGS.phenotype.no_missing.variable_transformation.csv \\\n",
    "                --iter \"${ITER}\" \\\n",
    "                --output_dir \"${OUT_DIR}\"/'\n",
    "\n",
    "print(\"\\n\".join(job_output))\n",
    "job_id = job_output[1].split(\" \")[-1]\n",
    "%env JOB_ID={job_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check worker status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dstat \\\n",
    "    --provider google-batch \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --location us-central1 \\\n",
    "    --jobs \"regression--kathleen-cardone--250922-223405-86\" \\\n",
    "    --users \"kathleen-cardone\" \\\n",
    "    --status '*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls ${WORKSPACE_BUCKET}/HF/output/regressions/train/ | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit next 500 jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "USER_NAME = os.getenv('OWNER_EMAIL').split('@')[0].replace('.','-')\n",
    "%env USER_NAME={USER_NAME}\n",
    "job_output = []\n",
    "\n",
    "\n",
    "JOB_NAME=f'regression'\n",
    "%env JOB_NAME={JOB_NAME}\n",
    "\n",
    "params_df = pd.DataFrame(data={\n",
    "    '--env ITER': list(range(501, 1001)),\n",
    "    '--output-recursive OUT_DIR': [f\"{bucket}/HF/output/regressions/train/\" for _ in range(500)]\n",
    "})\n",
    "\n",
    "PARAMETER_FILENAME = f'params.tsv'\n",
    "%env PARAMETER_FILENAME={PARAMETER_FILENAME}\n",
    "\n",
    "params_df.to_csv(PARAMETER_FILENAME, sep='\\t', index=False)\n",
    "\n",
    "print('submitting job')\n",
    "\n",
    "job_output = !source ~/aou_dsub.bash; aou_dsub \\\n",
    "  --name \"${JOB_NAME}\" \\\n",
    "  --provider google-batch \\\n",
    "  --image \"gcr.io/ritchie-aou-psom-9015/python:latest\" \\\n",
    "  --logging \"${WORKSPACE_BUCKET}/dsub_logs/hf/regressions/\" \\\n",
    "  --mount BUCKET=\"${WORKSPACE_BUCKET}\" \\\n",
    "  --tasks \"${PARAMETER_FILENAME}\" \\\n",
    "  --command 'python \"${BUCKET}\"/HF/scripts/hf_training_script.py \\\n",
    "                --input \"${BUCKET}\"/HF/input/HF_Clinical_PGS.phenotype.no_missing.variable_transformation.csv \\\n",
    "                --iter \"${ITER}\" \\\n",
    "                --output_dir \"${OUT_DIR}\"/'\n",
    "\n",
    "print(\"\\n\".join(job_output))\n",
    "job_id = job_output[1].split(\" \")[-1]\n",
    "%env JOB_ID={job_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dstat \\\n",
    "    --provider google-batch \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --location us-central1 \\\n",
    "    --jobs \"regression--kathleen-cardone--250922-224900-98\" \\\n",
    "    --users \"kathleen-cardone\" \\\n",
    "    --status '*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls ${WORKSPACE_BUCKET}/HF/output/regressions/train/ | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# evaluate IRM performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## copy inputs and script"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil cp hf_eval_script.py ${WORKSPACE_BUCKET}/HF/scripts/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp significant_vars_95.csv important_vars_95.csv LR_beta_all_iter.csv HF_Clinical_PGS.phenotype.no_missing.variable_transformation.csv ${WORKSPACE_BUCKET}/HF/input/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit first 500 jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "USER_NAME = os.getenv('OWNER_EMAIL').split('@')[0].replace('.','-')\n",
    "%env USER_NAME={USER_NAME}\n",
    "job_output = []\n",
    "\n",
    "\n",
    "JOB_NAME=f'eval'\n",
    "%env JOB_NAME={JOB_NAME}\n",
    "\n",
    "params_df = pd.DataFrame(data={\n",
    "    '--env ITER': list(range(1, 501)),\n",
    "    '--output-recursive OUT_DIR': [f\"{bucket}/HF/output/regressions/eval/\" for _ in range(500)]\n",
    "})\n",
    "\n",
    "PARAMETER_FILENAME = f'params.tsv'\n",
    "%env PARAMETER_FILENAME={PARAMETER_FILENAME}\n",
    "\n",
    "params_df.to_csv(PARAMETER_FILENAME, sep='\\t', index=False)\n",
    "\n",
    "print('submitting job')\n",
    "\n",
    "job_output = !source ~/aou_dsub.bash; aou_dsub \\\n",
    "  --name \"${JOB_NAME}\" \\\n",
    "  --provider google-batch \\\n",
    "  --image \"gcr.io/ritchie-aou-psom-9015/python:latest\" \\\n",
    "  --logging \"${WORKSPACE_BUCKET}/dsub_logs/hf/regressions/\" \\\n",
    "  --mount BUCKET=\"${WORKSPACE_BUCKET}\" \\\n",
    "  --tasks \"${PARAMETER_FILENAME}\" \\\n",
    "  --command 'python \"${BUCKET}\"/HF/scripts/hf_eval_script.py \\\n",
    "                --input \"${BUCKET}\"/HF/input/HF_Clinical_PGS.phenotype.no_missing.variable_transformation.csv \\\n",
    "                --sig \"${BUCKET}\"/HF/input/significant_vars_95.csv \\\n",
    "                --important \"${BUCKET}\"/HF/input/important_vars_95.csv \\\n",
    "                --beta \"${BUCKET}\"/HF/input/LR_beta_all_iter.csv \\\n",
    "                --iter \"${ITER}\" \\\n",
    "                --output_dir \"${OUT_DIR}\"/'\n",
    "\n",
    "print(\"\\n\".join(job_output))\n",
    "job_id = job_output[1].split(\" \")[-1]\n",
    "%env JOB_ID={job_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dstat \\\n",
    "    --provider google-batch \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --location us-central1 \\\n",
    "    --jobs \"eval--kathleen-cardone--250923-180411-31\" \\\n",
    "    --users \"kathleen-cardone\" \\\n",
    "    --status '*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls ${WORKSPACE_BUCKET}/HF/output/regressions/eval/ | wc -l"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## submit second 500 jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "bucket = os.getenv('WORKSPACE_BUCKET')\n",
    "USER_NAME = os.getenv('OWNER_EMAIL').split('@')[0].replace('.','-')\n",
    "%env USER_NAME={USER_NAME}\n",
    "job_output = []\n",
    "\n",
    "\n",
    "JOB_NAME=f'eval'\n",
    "%env JOB_NAME={JOB_NAME}\n",
    "\n",
    "params_df = pd.DataFrame(data={\n",
    "    '--env ITER': list(range(501, 1001)),\n",
    "    '--output-recursive OUT_DIR': [f\"{bucket}/HF/output/regressions/eval/\" for _ in range(500)]\n",
    "})\n",
    "\n",
    "PARAMETER_FILENAME = f'params.tsv'\n",
    "%env PARAMETER_FILENAME={PARAMETER_FILENAME}\n",
    "\n",
    "params_df.to_csv(PARAMETER_FILENAME, sep='\\t', index=False)\n",
    "\n",
    "print('submitting job')\n",
    "\n",
    "job_output = !source ~/aou_dsub.bash; aou_dsub \\\n",
    "  --name \"${JOB_NAME}\" \\\n",
    "  --provider google-batch \\\n",
    "  --image \"gcr.io/ritchie-aou-psom-9015/python:latest\" \\\n",
    "  --logging \"${WORKSPACE_BUCKET}/dsub_logs/hf/regressions/\" \\\n",
    "  --mount BUCKET=\"${WORKSPACE_BUCKET}\" \\\n",
    "  --tasks \"${PARAMETER_FILENAME}\" \\\n",
    "  --command 'python \"${BUCKET}\"/HF/scripts/hf_eval_script.py \\\n",
    "                --input \"${BUCKET}\"/HF/input/HF_Clinical_PGS.phenotype.no_missing.variable_transformation.csv \\\n",
    "                --sig \"${BUCKET}\"/HF/input/significant_vars_95.csv \\\n",
    "                --important \"${BUCKET}\"/HF/input/important_vars_95.csv \\\n",
    "                --beta \"${BUCKET}\"/HF/input/LR_beta_all_iter.csv \\\n",
    "                --iter \"${ITER}\" \\\n",
    "                --output_dir \"${OUT_DIR}\"/'\n",
    "\n",
    "print(\"\\n\".join(job_output))\n",
    "job_id = job_output[1].split(\" \")[-1]\n",
    "%env JOB_ID={job_id}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!dstat \\\n",
    "    --provider google-batch \\\n",
    "    --project \"${GOOGLE_PROJECT}\" \\\n",
    "    --location us-central1 \\\n",
    "    --jobs \"eval--kathleen-cardone--250923-181826-58\" \\\n",
    "    --users \"kathleen-cardone\" \\\n",
    "    --status '*'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## check output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil ls ${WORKSPACE_BUCKET}/HF/output/regressions/eval/ | wc -l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
